{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afa101e-a9e5-4d1d-9e3e-416f1c767233",
   "metadata": {},
   "source": [
    "# makemore part 4: Becoming a Backprop Ninja\n",
    "\n",
    "## What is makemore?\n",
    "\n",
    "Makemore \"makes more\" of things that you give it. Example uses `names.txt` and makemore learns to make names\n",
    "\n",
    "Under the hood, makemore is a character-level language model: it treats each line as sequences of individual characters. Model sequence of characters and try to predict next characters in a sequence.\n",
    "\n",
    "This class will look at \n",
    "1. Bigram (one character simply predicts a next one with a lookup table of counts)\n",
    "2. ~~Bag of Words~~\n",
    "   1. The table explodes! We'll skip\n",
    "3. **Multilayer Perceptron**\n",
    "4. Recurrent Neural Network\n",
    "5. GRU\n",
    "6. Transformers\n",
    "\n",
    "Will build a transformer equivalent to GPT-2, at the level of characters\n",
    "\n",
    "## Agenda\n",
    "Characters\n",
    "Words\n",
    "Images\n",
    "\n",
    "## Backprop\n",
    "\n",
    "In this lecture, we will manually work through backpropagation to see how it works and gain an intuitive undertanding of how gradients flow through the compute graph\n",
    "\n",
    "### Why?\n",
    "\n",
    "[Andrej wrote about this before](https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b)\n",
    "\n",
    "#### Trivia\n",
    "\n",
    "Deep learning used to be done in Matlab!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21b7d4-5980-4adf-a62b-38b8e89031ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b66d7b-46ad-4f10-9cb9-72c03e319fea",
   "metadata": {},
   "source": [
    "## External Resources\n",
    "\n",
    "### Lesson\n",
    "\n",
    "[Building makemore Part 4: Becoming a Backprop Ninja (youtube)](https://www.youtube.com/watch?v=q8SA3rM6ckI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a44e4-081e-4f8f-88d2-3eccd0f2d767",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418bdb7-3ecf-4eb5-af6f-2c0e699d2394",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f480787a-b5ed-4bf2-8553-504d6cfffe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60dd0a-089e-41b7-9828-8f2b13648993",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c3fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia', 'harper', 'evelyn']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "names_data = '../../data/raw/names.txt'\n",
    "\n",
    "words = open(names_data, 'r').read().splitlines()\n",
    "\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453979f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i  in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83312728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset but via a function instead\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "    \n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])        #80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])    #10%\n",
    "Xte, Yte = build_dataset(words[n2:])        #10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb59fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbed2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "# MLP revisited\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3) / ((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1 # using b1 just for fun, it's useless because of the BatchNormalization layer\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden,vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.zeros((1, n_hidden)) * 0.1\n",
    "\n",
    "# Note: I am initializing many of these parameters in non-standard ways because sometimes initializing with e.g. all zeros could mask an incorrect implementation of the backward pass\n",
    "# bnmean_running = torch.zeros((1, n_hidden))\n",
    "# bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02860e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa64c3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8279, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "\n",
    "# BatchNorm layer \n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0,keepdim=True) # note: Bessel's corection (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "\n",
    "# linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) isntead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw, \n",
    "          bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani, \n",
    "          embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6c9d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7b93326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 12,  0,  5,  9, 18,  9, 16,  1,  0,  0,  1,  0,  0, 14, 12,  0,  0,\n",
       "         0,  8, 25,  5,  0, 20, 19, 15, 12, 22, 22,  2, 21, 18])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1e9a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.4737, -1.5997, -4.0965, -3.4163, -2.8133, -4.0841, -4.6294, -4.3522,\n",
       "         -3.4315, -3.8062, -2.8183, -4.9644, -3.8716, -5.2169, -3.8951, -3.9360,\n",
       "         -3.6961, -5.1706, -6.1773, -4.1282, -1.9407, -3.1552, -2.5953, -4.3083,\n",
       "         -5.5041, -2.8096, -2.7644],\n",
       "        [-2.9138, -3.2064, -3.7923, -3.3294, -3.3902, -4.3600, -4.8044, -3.7086,\n",
       "         -2.5350, -3.3419, -3.7918, -5.3781, -4.0272, -2.8782, -4.6864, -3.2369,\n",
       "         -3.8677, -3.7333, -2.4258, -2.9420, -3.1745, -4.1116, -3.1403, -2.8597,\n",
       "         -2.8388, -5.0339, -2.3690],\n",
       "        [-3.7484, -3.3985, -2.4626, -4.2053, -3.7723, -3.5940, -3.1350, -3.3070,\n",
       "         -3.0667, -2.5784, -2.7553, -4.6368, -4.3291, -4.5310, -2.3343, -1.9610,\n",
       "         -4.8877, -3.0120, -2.7876, -5.5230, -3.6382, -4.2432, -4.2182, -5.7343,\n",
       "         -3.4217, -3.7083, -4.0801],\n",
       "        [-3.9838, -2.4010, -2.7263, -2.3265, -3.9493, -3.6299, -3.8739, -3.3855,\n",
       "         -3.5099, -4.8184, -2.9144, -2.9181, -3.7459, -3.8523, -4.5294, -3.1763,\n",
       "         -3.2556, -4.8025, -3.4802, -4.3971, -3.2079, -4.2644, -3.7212, -4.0124,\n",
       "         -4.7249, -2.1831, -2.5852],\n",
       "        [-3.4995, -3.4694, -2.5669, -4.1863, -3.8686, -5.0180, -1.9669, -3.2928,\n",
       "         -2.8162, -3.3076, -2.6968, -3.7315, -3.9809, -3.3426, -4.2626, -3.2771,\n",
       "         -4.5167, -3.3957, -2.1682, -4.2761, -3.2071, -4.9558, -4.3077, -3.5589,\n",
       "         -3.3363, -4.1595, -3.3487],\n",
       "        [-5.6027, -2.0862, -3.8256, -3.9060, -3.3517, -2.5721, -3.1189, -3.1317,\n",
       "         -5.4796, -4.3782, -3.9322, -1.9352, -3.7865, -4.4879, -3.0861, -4.5910,\n",
       "         -3.2932, -3.7728, -4.8307, -4.4640, -3.3655, -2.2934, -4.3984, -3.9781,\n",
       "         -2.9646, -3.4080, -3.5160],\n",
       "        [-3.6057, -3.1068, -3.6174, -3.9056, -3.9833, -3.3370, -3.4793, -4.6459,\n",
       "         -4.1258, -5.1132, -5.3862, -2.3495, -2.6016, -3.3324, -1.8088, -4.9851,\n",
       "         -4.3004, -2.5094, -4.1632, -4.7237, -4.2062, -4.5524, -3.1852, -2.8460,\n",
       "         -4.0692, -3.6534, -2.3373],\n",
       "        [-2.4859, -3.6805, -2.6652, -2.7295, -4.7681, -4.5675, -4.3652, -3.0623,\n",
       "         -2.4303, -4.6254, -4.2429, -2.5586, -3.8979, -3.8881, -2.9462, -3.8602,\n",
       "         -3.9004, -2.5566, -3.0399, -4.2140, -3.5414, -3.0070, -3.5509, -3.3941,\n",
       "         -3.7952, -3.6181, -3.7320],\n",
       "        [-3.3858, -3.6930, -4.2008, -2.8008, -4.0487, -4.6017, -3.1385, -2.6222,\n",
       "         -3.6480, -3.6869, -3.5026, -3.8357, -2.7522, -2.8676, -3.7252, -2.6456,\n",
       "         -2.6338, -3.7922, -4.4323, -3.4427, -3.1495, -3.3802, -2.3313, -3.1875,\n",
       "         -3.6064, -4.0494, -5.2234],\n",
       "        [-4.7350, -2.1887, -5.1083, -4.5314, -1.9289, -2.6047, -3.3189, -3.1638,\n",
       "         -3.8426, -4.1957, -2.7545, -4.3665, -4.0008, -3.7665, -3.0898, -3.9510,\n",
       "         -4.8663, -3.9324, -4.1477, -4.3618, -3.2146, -2.5033, -2.8089, -5.3278,\n",
       "         -3.1959, -3.8520, -3.2065],\n",
       "        [-3.7821, -3.8600, -4.9602, -3.5232, -4.5092, -2.0228, -6.2106, -4.2419,\n",
       "         -1.9086, -4.8736, -5.4420, -3.5464, -3.5509, -4.9680, -1.3345, -5.2419,\n",
       "         -5.1219, -3.7002, -5.6281, -4.4618, -5.0393, -2.9030, -2.5268, -3.8138,\n",
       "         -3.8706, -3.4317, -5.4433],\n",
       "        [-3.0043, -4.3303, -3.4355, -3.0837, -2.7197, -4.2219, -4.1695, -3.0420,\n",
       "         -3.0631, -3.5059, -3.9171, -3.1117, -4.0304, -4.3173, -3.6467, -2.8414,\n",
       "         -3.7953, -3.4422, -3.5882, -2.7822, -4.5542, -4.5663, -4.6544, -4.7704,\n",
       "         -1.6120, -4.5719, -2.7177],\n",
       "        [-4.6160, -4.3861, -2.8848, -6.3775, -2.4341, -1.6824, -2.5905, -3.0582,\n",
       "         -4.5720, -2.8897, -2.9277, -4.1180, -4.0635, -4.1682, -4.0551, -3.8932,\n",
       "         -4.3942, -3.4863, -2.3524, -3.8473, -3.0078, -3.9851, -4.6600, -4.8201,\n",
       "         -4.5330, -3.0793, -4.0906],\n",
       "        [-3.4832, -4.8179, -3.8082, -3.6531, -3.6620, -1.5948, -4.9189, -5.0424,\n",
       "         -2.0418, -4.5060, -4.7523, -3.9298, -3.0815, -3.9371, -2.9042, -5.1007,\n",
       "         -4.2645, -3.3864, -5.8109, -3.3383, -3.4241, -3.7157, -2.1343, -2.7671,\n",
       "         -3.6937, -3.8628, -5.3063],\n",
       "        [-4.8498, -3.6347, -4.8945, -3.7496, -2.4574, -4.2958, -5.0666, -2.1258,\n",
       "         -4.6373, -4.0721, -4.3437, -4.1736, -4.6270, -3.2338, -4.9639, -2.5255,\n",
       "         -2.9950, -5.3013, -3.0171, -1.9863, -4.1132, -4.7355, -3.8103, -3.3952,\n",
       "         -1.7880, -4.5295, -3.9914],\n",
       "        [-3.7048, -4.7499, -2.7924, -4.8142, -3.1107, -3.7113, -4.0721, -4.0396,\n",
       "         -4.3369, -1.5879, -2.5871, -5.8319, -3.6120, -3.3575, -4.1981, -3.0420,\n",
       "         -4.8262, -3.9804, -3.3484, -2.6454, -4.2913, -4.8622, -4.5949, -3.8249,\n",
       "         -2.9932, -4.7032, -2.0545],\n",
       "        [-5.1593, -3.7919, -3.9933, -3.2582, -2.7944, -3.3327, -4.8048, -3.3353,\n",
       "         -4.4367, -3.8081, -1.8804, -4.0306, -2.7706, -4.1764, -2.8198, -2.9331,\n",
       "         -3.9704, -4.8364, -5.3336, -3.0824, -4.4498, -3.7043, -2.8704, -3.9689,\n",
       "         -2.1817, -4.2619, -2.7688],\n",
       "        [-3.8163, -4.0146, -3.2897, -5.2312, -2.1284, -1.2898, -2.8912, -4.6576,\n",
       "         -3.5800, -3.7470, -3.3833, -5.0850, -2.9381, -5.0091, -4.4990, -3.9947,\n",
       "         -4.8333, -2.8436, -4.4641, -3.9932, -2.2448, -4.9346, -3.3213, -5.1848,\n",
       "         -4.4322, -4.5491, -5.5827],\n",
       "        [-4.4858, -5.5835, -3.3537, -6.4971, -2.4290, -1.4018, -5.1655, -6.0777,\n",
       "         -5.5652, -4.3249, -5.0578, -3.8569, -2.7319, -2.5209, -4.0808, -5.3816,\n",
       "         -3.9419, -3.0153, -4.0299, -4.7396, -3.2595, -5.7780, -4.0515, -1.8405,\n",
       "         -4.3217, -2.9210, -4.2043],\n",
       "        [-2.4859, -3.6805, -2.6652, -2.7295, -4.7681, -4.5675, -4.3652, -3.0623,\n",
       "         -2.4303, -4.6254, -4.2429, -2.5586, -3.8979, -3.8881, -2.9462, -3.8602,\n",
       "         -3.9004, -2.5566, -3.0399, -4.2140, -3.5414, -3.0070, -3.5509, -3.3941,\n",
       "         -3.7952, -3.6181, -3.7320],\n",
       "        [-4.9527, -3.9317, -2.7127, -5.8870, -2.3433, -3.3179, -2.7767, -4.7546,\n",
       "         -6.5922, -2.0625, -2.6524, -4.9539, -3.7812, -4.1441, -4.0756, -3.5779,\n",
       "         -3.7001, -2.4446, -2.9989, -4.2989, -2.9270, -2.6702, -5.0514, -3.7509,\n",
       "         -4.9697, -3.4927, -3.0677],\n",
       "        [-3.1368, -3.6631, -4.1932, -2.7160, -3.4193, -5.2744, -3.8253, -3.7243,\n",
       "         -2.6433, -2.4626, -5.2342, -3.6551, -3.8858, -3.1500, -3.5706, -3.6325,\n",
       "         -2.8384, -3.6016, -3.5668, -4.5765, -1.9371, -2.4922, -3.1763, -3.7192,\n",
       "         -4.3407, -3.9160, -4.5786],\n",
       "        [-2.4229, -3.8036, -3.9501, -2.8910, -3.1097, -3.2940, -3.5136, -4.1208,\n",
       "         -2.5009, -3.2718, -3.5657, -4.3481, -3.3537, -3.6630, -4.7477, -4.0586,\n",
       "         -4.6906, -3.4926, -3.2611, -2.2038, -2.9148, -5.9458, -2.8101, -2.7381,\n",
       "         -3.1818, -4.2255, -4.3717],\n",
       "        [-2.9283, -4.0318, -3.9313, -3.6354, -3.2882, -3.7571, -3.9231, -3.7977,\n",
       "         -3.1876, -2.5677, -3.5830, -5.8252, -4.0673, -2.1713, -4.6269, -3.7404,\n",
       "         -4.4901, -3.4731, -2.2352, -2.7159, -4.0030, -4.3366, -3.6559, -2.8756,\n",
       "         -4.5171, -3.7340, -2.2755],\n",
       "        [-4.0161, -3.1087, -3.6822, -2.3394, -3.1206, -3.2018, -3.5843, -3.0731,\n",
       "         -4.4108, -4.3305, -4.5016, -2.2029, -3.1282, -4.3290, -3.8008, -2.7984,\n",
       "         -3.9081, -3.8075, -3.8528, -3.6568, -3.2786, -4.6904, -3.8651, -4.0354,\n",
       "         -1.7500, -4.6406, -4.4616],\n",
       "        [-2.8416, -3.2127, -2.2061, -2.1787, -4.9115, -4.8652, -3.4535, -3.3021,\n",
       "         -3.3174, -2.9933, -3.9331, -3.1132, -4.0304, -2.9543, -3.9397, -2.7276,\n",
       "         -3.4770, -3.5844, -3.4013, -4.2448, -3.8773, -3.7683, -3.1421, -3.8519,\n",
       "         -4.5381, -3.1378, -3.8705],\n",
       "        [-4.0467, -3.3899, -5.0360, -3.0568, -2.2209, -4.1142, -4.5776, -2.7652,\n",
       "         -3.6063, -2.8185, -3.7736, -4.7985, -5.0097, -2.9209, -4.9145, -3.4211,\n",
       "         -3.3044, -5.5701, -3.9535, -1.6251, -3.8635, -4.6391, -3.9954, -3.2905,\n",
       "         -2.2679, -4.1617, -4.1018],\n",
       "        [-2.7819, -3.5616, -2.5078, -2.6879, -5.6185, -5.3139, -3.1112, -3.3983,\n",
       "         -2.9708, -3.5943, -3.4817, -3.0224, -3.5455, -3.2992, -3.0173, -3.4332,\n",
       "         -4.2585, -2.5362, -3.4801, -4.2799, -4.2758, -3.6387, -3.2933, -2.7496,\n",
       "         -3.1661, -3.4034, -4.2785],\n",
       "        [-2.3354, -2.7975, -3.1637, -2.4640, -4.7852, -4.4946, -2.8920, -4.0864,\n",
       "         -2.6583, -4.2437, -6.0280, -2.9251, -3.1505, -3.3938, -3.4692, -4.3615,\n",
       "         -4.0412, -3.0239, -2.9757, -4.0937, -3.8605, -5.2377, -4.8807, -3.7279,\n",
       "         -2.1785, -4.3955, -3.1034],\n",
       "        [-2.4859, -3.6805, -2.6652, -2.7295, -4.7681, -4.5675, -4.3652, -3.0623,\n",
       "         -2.4303, -4.6254, -4.2429, -2.5586, -3.8979, -3.8881, -2.9462, -3.8602,\n",
       "         -3.9004, -2.5566, -3.0399, -4.2140, -3.5414, -3.0070, -3.5509, -3.3941,\n",
       "         -3.7952, -3.6181, -3.7320],\n",
       "        [-2.6846, -3.7348, -3.2218, -2.4258, -4.1101, -5.0490, -3.8185, -3.2429,\n",
       "         -2.0854, -3.3077, -4.6673, -2.5227, -4.8704, -4.0272, -3.1714, -2.9950,\n",
       "         -3.7396, -3.0925, -3.1162, -4.7191, -2.9004, -2.7636, -4.4860, -4.5852,\n",
       "         -3.9170, -3.3045, -4.6864],\n",
       "        [-2.4859, -3.6805, -2.6652, -2.7295, -4.7681, -4.5675, -4.3652, -3.0623,\n",
       "         -2.4303, -4.6254, -4.2429, -2.5586, -3.8979, -3.8881, -2.9462, -3.8602,\n",
       "         -3.9004, -2.5566, -3.0399, -4.2140, -3.5414, -3.0070, -3.5509, -3.3941,\n",
       "         -3.7952, -3.6181, -3.7320]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44bfc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = -(a + b + c) / 3\n",
    "# dloss/da = -1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96d0e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, backpropagating through exactly all of the variables as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "# cmp('bndiff2', dbndiff2, bndiff2)\n",
    "# cmp('bnmeani', dbnmeani, bnmeani)\n",
    "# cmp('hprebn', dhprebn, hprebn)\n",
    "# cmp('embcat', dembcat, embcat)\n",
    "# cmp('W1', dW1, W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8c016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecbec2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d75ca9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9264ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "604b24cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfbb2ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dnorm_logits = counts * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e164498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b5ef73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed720e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogits = dnorm_logits.clone()\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ca7a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dh = dlogits @ W2.T \n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04224667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bd37cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngain          | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "203b1a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
      "bndiff          | exact: False | approximate: False | maxdiff: 0.0012138168094679713\n"
     ]
    }
   ],
   "source": [
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "\n",
    "\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "\n",
    "\n",
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff70392",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
