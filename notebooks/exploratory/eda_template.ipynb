{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afa101e-a9e5-4d1d-9e3e-416f1c767233",
   "metadata": {},
   "source": [
    "# TITLE OF NOTEBOOK\n",
    "\n",
    "This is an idealized workflow for Aaron Chen in looking at data science problems. It likely isn't the best path, nor has he rigidly applied or stuck to this ideal, but he wishes that he worked this way more frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59c575-9aca-4d08-9b03-3425fa33cb03",
   "metadata": {},
   "source": [
    "## Purpose: Write out what you want the notebook to do\n",
    "\n",
    "### Author: AUTHOR NAME\n",
    "This is of questionable value. I'd say having the author helps with notebooks, but may not be necessary with items that have more integration with git (like Python scripts). It's more helpful with notebooks because git tends to track changes in notebooks that are more similar to XML changes and it can be harder to see who is doing what inside a notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21b7d4-5980-4adf-a62b-38b8e89031ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d4a89-cf20-435c-bcc0-6f1ebcd127c7",
   "metadata": {},
   "source": [
    "### If needed, run shell commands here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ed4e2d-6f77-4196-b548-d5896e13193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cede1d1-3a00-4471-91ae-50be260464a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b66d7b-46ad-4f10-9cb9-72c03e319fea",
   "metadata": {},
   "source": [
    "## External Resources\n",
    "\n",
    "List out references or documentation that has helped you with this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b23fd3-6cf1-42b3-aee3-82306eaade6a",
   "metadata": {},
   "source": [
    "### Code\n",
    "Regex Checker: https://regex101.com/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf83f44-334c-448a-afa7-187f63dd7285",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "For this notebook, the data is stored in the repo base folder/data/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dcb8e-5a84-4e96-b07d-24909352935d",
   "metadata": {},
   "source": [
    "### Process\n",
    "\n",
    "Are there steps or tutorials you are following? Those are things I try to list in Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a44e4-081e-4f8f-88d2-3eccd0f2d767",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418bdb7-3ecf-4eb5-af6f-2c0e699d2394",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f480787a-b5ed-4bf2-8553-504d6cfffe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_sm\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, Phrases\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.spacy\n",
    "import logging\n",
    "import dvc.api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60dd0a-089e-41b7-9828-8f2b13648993",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde95259-0cd4-4ae1-8485-d51ada957529",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3ea1e-a26e-4545-b950-ec823cbd6a26",
   "metadata": {},
   "source": [
    "My workflow is to try things with code cells, then when the code cells get messy and repetitive, to convert into helper functions that can be called.\n",
    "\n",
    "When the helper functions are getting used a lot, it is usually better to convert them to scripts or classes that can be called/instantiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32db6018-d8b8-492f-927e-f1e7d7398588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empties(deficiency_text: List) -> List:\n",
    "    \"\"\"This function takes in a list of strings and removes empty strings from the list. The function is needed \n",
    "    because if the list does not contain empty strings, the default remove() function returns None and an Error.\"\"\"\n",
    "    \n",
    "    filtered = list(filter(lambda x: x != '', deficiency_text))\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6fb08d-a266-4785-8d88-e2a3ca89cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lemmatizer(doc):\n",
    "#     # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "#     # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "#     doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "#     doc = u' '.join(doc)\n",
    "#     return nlp.make_doc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b37e7b8-fa9c-45b5-96c1-fde99ed40f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stopwords(doc):\n",
    "#     # This will remove stopwords and punctuation.\n",
    "#     # Use token.text to return strings, which we'll need for Gensim.\n",
    "#     doc = [token for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "#     return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10554bde-9215-47dc-a90d-9bc53fc7d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.add_pipe(lemmatizer,name='lemmatizer',after='ner')\n",
    "# nlp.add_pipe(remove_stopwords, name=\"stopwords\", last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fdd4b0-9acb-445e-acad-2b3eb6ab9e4c",
   "metadata": {},
   "source": [
    "### Import local script\n",
    "\n",
    "I started grouping this in with importing libraries, but putting them at the bottom of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ae4f42-17a3-4564-95b7-7993e5989d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import project_path\n",
    "# import src.nhsn_vac_df_builder as nhsn_vac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b7742-3b22-4f48-877f-9f32cd7251fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7445bf0-0b00-45b9-a2db-84c568bced29",
   "metadata": {},
   "source": [
    "## Define global variables \n",
    "### Remember to refactor these out, not ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00c380-63ee-4141-a073-fbe725cb826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "filepath = \"../../data/raw/statements_of_deficiencies_public.csv\"\n",
    "repo = '/Users/c86w/Repos/Form_2567_NLP'\n",
    "version ='v0.2'\n",
    "\n",
    "data_url = dvc.api.get_url(path=filepath,repo=repo,rev=version)\n",
    "\n",
    "mlflow.set_experiment(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab98b748-74ad-4dff-bebe-aa794f7a4591",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325f7ef-07c7-46b1-8595-9749259da76b",
   "metadata": {},
   "source": [
    "## Running Commentary\n",
    "\n",
    "1. I used numbered lists to keep track of things I noticed\n",
    "\n",
    "### To Do\n",
    "\n",
    "1. List tasks here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2173e5-db8a-4fff-8072-98d6b16f7a4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf870da-c2ed-4cde-9dd8-1591cbd2f24c",
   "metadata": {},
   "source": [
    "## Try to further divide work into sections. With Table of Contents extension you should be able to jump to sections more easily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401fb53",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2567_nlp",
   "language": "python",
   "name": "2567_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
